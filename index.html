<!DOCTYPE HTML>
<!--
	Astral by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Zhe-chen Guo</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<base target="_blank">
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper-->
			<div id="wrapper">

				<!-- Nav -->
					<nav id="nav">
						<a href="#" class="icon solid fa-home" target="_self"><span>Home</span></a>
						<a href="#publications" class="icon solid fa-book"><span>Publications</span></a>
						<a href="#presentations" class="icon solid fa-chalkboard-teacher"><span>Presentations</span></a>
						<a href="#contact" class="icon solid fa-envelope-open-text"><span>Contact</span></a>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Me -->
							<article id="home" class="panel intro">
								<header>
									<h1 style="font-size: 1.5em;">Zhe-chen Guo</h1>
									<p style="font-size: 0.9em;line-height: 1.2;text-align: justify;">Hello! I'm a Postdoctoral Scholar in <a href="https://soundbrainlab.northwestern.edu/">Dr. Bharath Chandrasekaran's SoundBrain Lab</a> at Northwestern University. My research revolves around phonetics and speech perception. I use a combination of behavioral, neurophysiological, and computational methods to explore how listeners process continuous speech in various listening conditions and how speech features are represented in the brain. Currently, I'm studying the neural encoding of phonemes and pitch accents through deep neural network modeling of speech-evoked EEG responses.</p>
									<p style="font-size: 0.9em; line-height: 1.2;text-align: justify;">Prior to joining Northwestern, I earned my PhD in Linguistics from the University of Texas at Austin, where I conducted a series of experiments under the supervision of <a href="https://utsoundlab.wordpress.com/">Dr. Rajka Smiljanic</a> to examine clear speech benefits for word segmentation and coarticulation of clear speech across communicative contexts.</p>
									<p><a href="files/zc_guo_CV.pdf">My CV here</a></p>
								</header>
								<a href="#publications" class="jumplink pic" title = "Welcome!" target="_self">
									<span class="arrow icon solid fa-chevron-right"><span>See my work</span></span>
									<img src="images/welcome.png" alt="" />
								</a>
							</article>

						<!-- Publications -->
							<article id="publications" class="panel">
								<header>
									<h2>Publications</h2>
								</header>
								<h3>
									Peer-reviwed journal papers:
								</h3>
								<ol>
									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (under review). Ham or hamster? Eye-tracking evidence of clear speech benefit for word segmentation in quiet and in noise.</li>

									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (2023). Speakers coarticulate less in response to both real and imagined communicative challenges: An acoustic analysis of the LUCID corpus. <i>Journal of Phonetics</i>, <i>97</i>, 101210. <a href="https://doi.org/10.1016/j.wocn.2022.101210">https://doi.org/10.1016/j.wocn.2022.101210</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2022). The effect of lengthening aspiration on speech segmentation. <i>JASA Express Letters</i>, <i>2</i>(4), 045202. <a href="https://doi.org/10.1121/10.0010242">https://doi.org/10.1121/10.0010242</a></li>

									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (2021). Speaking clearly improves speech segmentation by statistical learning under optimal listening conditions. <i>Laboratory Phonology: Journal of the Association for Laboratory Phonology</i>, <i>12</i>(1), 14. <a href="https://doi.org/10.5334/labphon.310">https://doi.org/10.5334/labphon.310</a></li>

									<li><strong>Guo, Z.-C.</strong>, & Ou, S.-C. (2021). The use of tonal coarticulation in segmentation of artificial language speech: A study with Mandarin listeners. <i>Applied Psycholinguistics</i>, <i>42</i>(3), 631–655. <a href="https://doi.org/10.1017/S0142716420000818">https://doi.org/10.1017/S0142716420000818</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2021). The language-specific use of F0 rise in segmentation of an artificial language: Evidence from listeners of Taiwanese Southern Min. <i>Language and Speech</i>, <i>64</i>(2), 437–466. <a href="https://doi.org/10.1177/0023830919886604">https://doi.org/10.1177/0023830919886604</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2021). The differential effects of vowel and onset consonant lengthening on speech segmentation: Evidence from Taiwanese Southern Min. <i>The Journal of Acoustical Society of America</i>, <i>149</i>(3), 1866–1877. <a href="https://doi.org/10.1121/10.0003751">https://doi.org/10.1121/10.0003751</a></li>
									
									<li><strong>Guo, Z.-C.</strong>, & Ou, S.-C. (2014). Perception of articulatorily different Mandarin retroflexes by Japanese speakers: A pilot study. <i>NTU Working Papers in Chinese Language Teaching</i>, <i>2</i>, 1–28. Taipei: National Taiwan University. <a href="http://dx.doi.org/10.6664%2fNTUTCSL.201408_(2).0004">http://dx.doi.org/10.6664%2fNTUTCSL.201408_(2).0004</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2014). Mandarin retroflex sounds perceived by non-native speakers. <i>Journal of Language and Literature Studies</i>, <i>26</i>, 41–76.</li>
								</ol>
								<h3>
									Peer-reviewed conference proceedings:
								</h3>
								<ol>
									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (2023). Clear speech facilitates word segmentation: Evidence from eye-tracking. In Radek Skarnitzl & Jan Volín (Eds.), <i>Proceedings of the 20th International Congress of Phonetic Sciences</i> (pp. 177–181). Guarant International.<br>
									(Also orally presented, Prague, Czech, August 7–11) <a href="https://guarant.cz/icphs2023/283.pdf">[paper]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2023). The effect of shortening onset consonants on speech segmentation by Taiwanese Southern Min listeners. In Radek Skarnitzl & Jan Volín (Eds.), <i>Proceedings of the 20th International Congress of Phonetic Sciences</i> (pp. 167–171). Guarant International.<br>
									(Also presented in poster format, Prague, Czech, August 7–11) <a href="https://guarant.cz/icphs2023/268.pdf">[paper]</a> <a href="files/posters/Ou_Guo_2023_ICPhS_poster_Prague.pdf">[poster]</a></li>

									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (2021). Speakers coarticulate less when facing real and imagined communicative difficulties: An analysis of read and spontaneous speech from the LUCID corpus. In <i>Proceedings of Interspeech 2021</i> (pp. 4009–4013). <a href="http://dx.doi.org/10.21437/Interspeech.2021-1640">http://dx.doi.org/10.21437/Interspeech.2021-1640</a><br>
									(Also presented virtually, Brno, Czechia, August 30–September 3)</li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2020). The opposite effects of vowel and onset consonant lengthening on speech segmentation. In <i>Proceedings of the 10th International Conference on Speech Prosody</i>. <a href="https://doi.org/10.21437/SpeechProsody.2020-16">https://doi.org/10.21437/SpeechProsody.2020-16</a><br>
									(Also presented virtually, Tokyo, Japan, May 24–28)</li>

									<li><strong>Guo, Z.-C.</strong>, & Ou, S.-C. (2019). The use of tonal coarticulation in speech segmentation by listeners of Mandarin. In S. Calhoun, P. Escudero, M. Tabain, & P. Warren (Eds.), <i>Proceedings of the 19th International Congress of Phonetic Sciences</i> (pp. 2017–2021).<br>
									(Also orally presented, Melbourne, Australia, August 4–10) <a href="http://intro2psycholing.net/ICPhS/papers/ICPhS_2066.pdf">[paper]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2019). The role of initial F0 rise in speech segmentation: A cross-linguistic study. S. Calhoun, P. Escudero, M. Tabain, & P. Warren (Eds.), <i>Proceedings of the 19th International Congress of Phonetic Sciences</i> (pp. 2916–2920).<br>
									(Also presented in poster format, Melbourne, Australia, August 4–10) <a href="http://intro2psycholing.net/ICPhS/papers/ICPhS_2965.pdf">[paper]</a> <a href="files/posters/Ou_Guo_2019_ICPhS_poster_Melbourne.pdf">[poster]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2015). The effect of stress on English word recognition by native speakers of typologically different languages. In The Scottish Consortium for ICPhS 2015, <i>Proceedings of the 18th International Congress of Phonetic Sciences</i>.<br>
									(Also orally presented, Glasgow, UK, August 10–14.) <a href="https://www.internationalphoneticassociation.org/icphs-proceedings/ICPhS2015/Papers/ICPHS0373.pdf" target="_blank">[paper]</a></li>
								</ol>
							</article>

						<!-- Presentations -->
							<article id="presentations" class="panel">
								<header>
									<h2>Presentations</h2>
								</header>
								<p style="font-size: 0.8em;line-height: 0.4em;">*: Listed as citable abstract</p>
								<ol>
									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (2023). Clear speech benefit for word segmentation is modulated by contextual-semantic cues: Evidence from eye-tracking. The <i>Psychonomic Society 64th Annual Meeting</i>, San Francisco, California, November 16–19. <a href="files/posters/Guo_Smiljanic_2023_Psychonomics_poster_San_Francisco.pdf">[poster]</a></li>

									<li><strong>*Guo, Z.-C.</strong>, Pangottil, K., Chandrasekaran, B., & Llanos, F. (2023). Decoding speech envelopes from electroencephalographic recordings: A comparison of regularized linear regression and long short-term memory deep neural network. <i>The Journal of the Acoustical Society of America</i>, <i>153</i>(3), A158. <a href="https://doi.org/10.1121/10.0018496">https://doi.org/10.1121/10.0018496</a><br>
									(Poster presentation at the <i>184th Meeting of the Acoustical Society of America</i>, Chicago, May 8–12) <a href="files/posters/Guo_et_al_2023_ASA_poster_Chicago.pdf">[poster]</a></li>

									<li><strong>*Guo, Z.-C.</strong>, Smiljanic, R. (2023). Clear speech improves word segmentation in quiet and in noise: Evidence from visual-world eye-tracking. <i>The Journal of the Acoustical Society of America</i>, <i>153</i>(3), A168. <a href="https://doi.org/10.1121/10.0018543">https://doi.org/10.1121/10.0018543</a><br>
									(Poster presentation at the <i>184th Meeting of the Acoustical Society of America</i>, Chicago, May 8–12) <a href="files/posters/Guo_Smiljanic_2023_ASA_poster_Chicago.pdf">[poster]</a></li>

									<li><strong>*Guo, Z.-C.</strong>, Smiljanic, R. (2022). Coarticulation is reduced in clear speech produced with protective face masks. <i>The Journal of the Acoustical Society of America</i>, <i>152</i>(4), A286. <a href="https://doi.org/10.1121/10.0016295">https://doi.org/10.1121/10.0016295</a><br>
									(Poster presentation at the <i>183rd Meeting of the Acoustical Society of America</i>, Nashville, December 5–9) <a href="files/posters/Guo_Smiljanic_2022_ASA_poster_Nashville.pdf">[poster]</a></li>

									<li>Dai, S., Frank, K., Jess, N., <strong>Guo, Z.-C.</strong> (2022). Network effects on Twitter users' language use and issue disposition of CRT: A machine learning approach investigating the influence model. Paper presented at the <i>2022 Midwest Sociology of Education Conference</i>, University of Notre Dame, Indiana, October 27–28.</li>

									<li><strong>Guo, Z.-C.</strong>, & Smiljanic, R. (2022). Coarticulatory vowel nasalization in read and listener-directed speech across communicative contexts: An analysis of the LUCID corpus. Paper presented at the <i>18th Conference on Laboratory Phonology (LabPhon 18)</i>, online conference, June 23–25</li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2022). Is onset-consonant lengthening a universal word beginning cue? A cross-linguistic study of English and French listeners. Paper presented virtually at the <i>29th Manchester Phonology Meeting</i>, May 25–27.</li>

									<li><strong>*Guo, Z.-C.</strong>, & Smiljanic, R. (2022). The degree and time course of nasal coarticulation across communicative contexts: A study of the LUCID corpus.<i>The Journal of the Acoustical Society of America</i>, <i>151</i>(4), A65. <a href="https://doi.org/10.1121/10.0010676">https://doi.org/10.1121/10.0010676</a><br>
									(Poster presentation at the <i>182nd Meeting of the Acoustical Society of America</i>, Denver, May 23–27.) <a href="files/posters/Guo_Smiljanic_2022_ASA_poster_Denver.pdf">[poster]</a></li>

									<li><strong>*Guo, Z.-C.</strong>, & Smiljanic, R. (2021). Coarticulation across communicative contexts: An acoustic analysis of the LUCID corpus using spectral and temporal measures. <i>The Journal of the Acoustical Society of America</i>, <i>150</i>(4), A70. <a href="https://doi.org/10.1121/10.0007659">https://doi.org/10.1121/10.0007659</a><br>
									(Poster presentation at the 181st meeting of the Acoustical Society of America, Seattle, November 29–December 3) <a href="files/posters/Guo_Smiljanic_2021_ASA_poster_Seattle.pdf">[poster]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2021). The effect of aspiration lengthening on speech segmentation: An artificial language learning study. Paper presented virtually at the <i>28th Manchester Phonology Meeting</i>, May 26–28. <a href="http://www.lel.ed.ac.uk/mfm/28mfm-abbk.pdf#page=36">[abstract]</a></li>

									<li><strong>*Guo, Z.-C.</strong> (2020). Tonal carryover assimilation is exploited as a speech segmentation cue in the case of cue conflict. <i>The Journal of the Acoustical Society of America</i>, <i>148</i>(4), 2504–2504. <a href="https://doi.org/10.1121/1.5146952">https://doi.org/10.1121/1.5146952</a><br>
									(Virtual poster presentation at the 179th Meeting of the Acoustical Society of America, December 7–11) <a href="https://ave20-asa.ipostersessions.com/default.aspx?s=E1-7B-11-0E-22-C0-B4-C2-72-46-4E-E2-C3-13-B3-5B">[poster]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2020). The effects of segment lengthening on speech segmentation. Paper presented at the <i>13th International Symposium on Taiwanese Languages and Teaching</i>, National Tsing Hua University, Hsinchu, October 16–17.</li>

									<li><strong>*Guo, Z.-C.</strong>, & Smiljanic, R. (2019). Speaking clearly improves speech segmentation in optimal listening conditions. <i>The Journal of the Acoustical Society of America</i>, <i>146</i>(4), 3052–3052. <a href="https://doi.org/10.1121/1.5137579">https://doi.org/10.1121/1.5137579</a><br>
									(Poster presentation at the 178th Meeting of the Acoustical Society of America, San Diego, California, December 2–6) <a href="files/posters/Guo_Smiljanic_2019_ASA_poster_San_Diego.pdf">[poster]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2018). The role of lexical tone in speech segmentation by listeners of Taiwanese Southern Min: A corpus and experimental study. Oral presentation at the <i>7th International Conference on Phonology and Morphology</i>, Seoul, Korea, June 29–30.</li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2017). The language-specific use of F0 rise in speech segmentation by listeners of Taiwanese Southern Min. Oral presentation at <i>2017 ILAS Workshop on Phonetics and Phonology</i>, Academia Sinica, Taipei, October 23–24.</li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2017). Is the cue of pitch rise to spoken word segmentation used in a language-specific or cross-linguistic way? A study of listeners of Taiwanese Southern Min. Oral presentation at the <i>Phonetics and Phonology in Europe 2017</i>, Cologne, Germany, June 12–14. <a href="https://pape2017.uni-koeln.de/wp-content/uploads/2016/01/abstractbook_site.pdf#page=94">[abstract]</a></li>

									<li>Ou, S.-C., & <strong>Guo, Z.-C.</strong> (2016). The use of lexical tone in spoken word segmentation by Taiwanese Southern Min listeners. Oral presentation at the <i>24th Annual Conference of the International Association of Chinese Linguistics</i>, Beijing, China, July 17–19</li>

									<li><strong>Guo, Z.-C.</strong> (2014). Perception of articulatorily different Mandarin retroflexes by Japanese speakers: A pilot study. Oral presentation at the <i>2nd NTU Postgraduate Conference on Teaching Chinese as a Second Language</i>, National Taiwan University, Taipei, March 29.</li>
								</ol>
							</article>

						<!-- Contact -->
							<article id="contact" class="panel">
								<header>
									<h2>Contact</h2>
									<div class="contact-icon">
										<div class="icon solid fa-at" style="font-size: 1.8em; width: 2.0em;"></div>
										<div class="contact-icon-text">zcguo@northwestern.edu</div>
									</div>
									<div class="contact-icon">
										<div class="icon solid fa-map-marker-alt" style="font-size: 1.8em; width: 2.0em;"></div>
										<div class="contact-icon-text" style="font-size: 1.0em">
											<pre style="white-space: pre-line;line-height: 1.2em;">
											Department of Communication Sciences and Disorders
											Frances Searle Building
											2240 Campus Drive
											Evanston, IL 60208
											</pre>
										</div>
									</div>

								<section>
									<h3 style="margin-top: 1.0em;">Researcher profiles</h3>
									<div class="container-icon">
										<div class="item-icon" style="background-color: #A6CC46;">
											<a href="https://orcid.org/0000-0003-0870-8321" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/orcid-brands.svg" class="filter-white" style="width: 2.3em;">
													<p>ORCID</p>
												</div>
											</a>
										</div>
										<div class="item-icon" style="background-color: #367BE8;">
											<a href="https://scholar.google.com/citations?user=TVH531MAAAAJ" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/google-scholar-resized.svg" class="filter-white" style="width: 2.3em;">
													<p style="font-size: 0.7em; margin: 0 0 2.7em 0;"> Google Scholar</p>
												</div>
											</a>
										</div>
									</div>

									<h3 style="margin-top: 1.0em;">Data repositories</h3>
									<div class="container-icon">
										<div class="item-icon" style="background-color: #222;">
											<a href="https://github.com/zc-guo" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/iconmonstr-github-1.svg" class="filter-white" style="width: 2.3em;">
													<p>GitHub</p>
												</div>
											</a>
										</div>
										<div class="item-icon" style="background-color: #36BBEF;">
											<a href="https://osf.io/4pq2c" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/osf-resized.svg" class="filter-white" style="width: 2.3em;">
													<p style="font-size:0.7em; line-height: 1.0em; text-align: center; margin: 0 0 2.7em 0;">Open Science<br>Framework</p>
												</div>
											</a>
										</div>
									</div>

									<h3 style="margin-top: 1.0em;">Social media</h3>
									<div class="container-icon">
										<div class="item-icon" style="background-color: #1569BF;">
											<a href="https://www.linkedin.com/in/zhe-chen-guo-a26043130/" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/iconmonstr-linkedin-3.svg" class="filter-white" style="width: 2.3em;">
													<p>LinkedIn</p>
												</div>
											</a>
										</div>
										<div class="item-icon" style="background-color: #E74D5A;">
											<a href="https://www.instagram.com/zcguo81/" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/iconmonstr-instagram-11.svg" class="filter-white" style="width: 2.3em;">
													<p>Instagram</p>
												</div>
											</a>
										</div>
										<div class="item-icon" style="background-color: #299DED;">
											<a href="https://twitter.com/zcguo81" target="_blank">
												<span class="helper-icon"></span>
												<div style="display: inline-block;vertical-align: middle;">
													<img src="assets/css/images/iconmonstr-twitter-1.svg" class="filter-white" style="width: 2.3em;">
													<p>Twitter</p>
												</div>
											</a>
										</div>
									</div>

								</section>

								</header>
							</article>

					</div>

				<!-- Footer -->
					<div id="footer">
						<ul class="copyright">
							<li>&copy; 2023 Zhe-chen Guo.</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
						</ul>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script src="assets/js/background-color.js"></script>

	</body>
</html>